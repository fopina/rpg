<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Random Post Generator</title><link>https://rpg.skmobi.com/posts/</link><description>Recent content in Posts on Random Post Generator</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 09 Apr 2021 01:37:29 +0100</lastBuildDate><atom:link href="https://rpg.skmobi.com/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>0x904Drop IPTables Drop</title><link>https://rpg.skmobi.com/posts/0x904d_cloudflare_pull/</link><pubDate>Fri, 09 Apr 2021 01:37:29 +0100</pubDate><guid>https://rpg.skmobi.com/posts/0x904d_cloudflare_pull/</guid><description>My houselab is made of a few RPis and docker swarm.
Traefik is used to expose (most of) the swarm services and some of these services are exposed to the internet.
Traefik docker-compose includes these flags
- --entrypoints.http.address=:80- --entrypoints.https.address=:443- --entrypoints.https_external.address=:8443Home router has port forwarding from 443 to 8443 on one of the manager nodes (where Traefik runs). Binding services to http (80) or https (443) exposes them internally only, binding to https_external (8443) exposes them to the internet.</description><content type="html"><![CDATA[<p>My houselab is made of a few RPis and docker swarm.<br>
Traefik is used to expose (most of) the swarm services and some of these services are exposed to the internet.</p>
<p>Traefik docker-compose includes these flags</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w"> </span>- --<span class="l">entrypoints.http.address=:80</span><span class="w">
</span><span class="w"> </span>- --<span class="l">entrypoints.https.address=:443</span><span class="w">
</span><span class="w"> </span>- --<span class="l">entrypoints.https_external.address=:8443</span><span class="w">
</span></code></pre></div><p>Home router has port forwarding from 443 to 8443 on one of the manager nodes (where Traefik runs). Binding services to <code>http</code> (80) or <code>https</code> (443) exposes them internally only, binding to <code>https_external</code> (8443) exposes them to the internet.</p>
<p>With this, service exposure is managed in the service docker-compose itself</p>
<p>Internal-only</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">deploy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">traefik.enable</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;true&#34;</span><span class="w">
</span><span class="w">      </span><span class="nt">traefik.docker.network</span><span class="p">:</span><span class="w"> </span><span class="l">traefik_default</span><span class="w">
</span><span class="w">      </span><span class="nt">traefik.http.services.myweb.loadbalancer.server.port</span><span class="p">:</span><span class="w"> </span><span class="m">9999</span><span class="w">
</span><span class="w">      </span><span class="nt">traefik.http.routers.myweb.rule</span><span class="p">:</span><span class="w"> </span><span class="l">Host(`myweb.internal`)</span><span class="w">
</span><span class="w">      </span><span class="nt">traefik.http.routers.myweb.entrypoints</span><span class="p">:</span><span class="w"> </span><span class="l">http</span><span class="w">
</span><span class="w">      </span><span class="nt">traefik.http.routers.myweb.middlewares</span><span class="p">:</span><span class="w"> </span><span class="l">https-only</span><span class="w">
</span></code></pre></div><p>Or the extra labels to make it external</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">      </span><span class="nt">traefik.http.routers.myweb_ext.rule</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Host(`myweb.skmobi.com`)&#34;</span><span class="w">
</span><span class="w">      </span><span class="nt">traefik.http.routers.myweb_ext.entrypoints</span><span class="p">:</span><span class="w"> </span><span class="l">https_external</span><span class="w">
</span></code></pre></div><p>To have some sort of extra security üîí, all of these domain are behind ‚òÅÔ∏è Cloudflare.<br>
In order to prevent anyone from bypassing it, I was using a simple <a href="https://github.com/fopina/ansible-roles/tree/main/cloudflare-ips">ansible role</a> in my RPi provisioning playbook to make sure the <a href="https://www.cloudflare.com/ips/">latest IP ranges from $NET</a> were set up in iptables.</p>
<p>When I read about their <a href="https://support.cloudflare.com/hc/en-us/articles/204899617">Authenticated Origin Pulls</a> I immediately added it to my backlog, as it&rsquo;s much cleaner to install a CA once than managing IP ranges in iptables.</p>
<p>And it would allow me to also have non-proxied services in the same port (based on SNI), even restrict those to my own client certificates (issued by the <a href="/posts/0x6fd7_docker_internal_ca/">same internal CA I use for server certificates</a>)</p>
<p>And it&rsquo;s safer as <a href="https://jychp.medium.com/how-to-bypass-cloudflare-bot-protection-1f2c6c0c36fb">IP ACLs are not that reliable</a>.</p>
<p>And probably overall performance is even better (<em>checking rules on every packet versus extra validation on TLS negotiation only</em>) - <strong>to be tested</strong> üîú</p>
<p>I left that <a href="https://help.trello.com/article/820-card-aging">Trello card age</a> for some time like a good wine and finally picked it up!</p>
<p>One quick option would be to spin up an <code>nginx</code> container, set it up as cloudflare <a href="https://support.cloudflare.com/hc/en-us/articles/204899617#h_2WFdI4xHJSAQ6GqBjgkfhb">documented</a>, <code>proxypass</code> all of it to traefik and change the port forward to nginx port instead.<br>
But that would require all services behind cloudflare instead of letting me choose per service. Plus, it&rsquo;d be yet another piece in the stack.</p>
<p>So let&rsquo;s get traefik to handle it!</p>
<p>Traefik has this <a href="https://doc.traefik.io/traefik/routing/routers/#options">tls.options</a> available both at entrypoint level and router level. But sadly, it&rsquo;s not possible to configure each parameter with labels (<a href="https://github.com/traefik/traefik/issues/5507">yet</a>).</p>
<p>Enter dynamic configuration! Create some file somewhere, such as <code>/etc/traefik/dynamic/tlsoptions.yaml</code>, with</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">tls</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">options</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">cfcert</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">clientAuth</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">caFiles</span><span class="p">:</span><span class="w">
</span><span class="w">          </span>- <span class="l">/etc/traefik/dynamic/origin-pull-ca.pem</span><span class="w">
</span><span class="w">        </span><span class="nt">clientAuthType</span><span class="p">:</span><span class="w"> </span><span class="l">RequireAndVerifyClientCert</span><span class="w">
</span></code></pre></div><p>Place the <a href="https://support.cloudflare.com/hc/en-us/article_attachments/360044928032/origin-pull-ca.pem">cloudflare-provided origin-pull-ca.pem</a> and add this conf to traefik (CLI flag)</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">- --<span class="l">providers.file.directory=/etc/traefik/dynamic</span><span class="w">
</span></code></pre></div><p>Now, if some service should be only accessible through cloudflare, I only need to add one extra label, with the new <code>tls.options</code> <code>cfcert</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">      </span><span class="nt">traefik.http.routers.myweb_ext.entrypoints</span><span class="p">:</span><span class="w"> </span><span class="l">https_external</span><span class="w">
</span><span class="w">      </span><span class="nt">traefik.http.routers.myweb_ext.tls.options</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;cfcert@file&#34;</span><span class="w">
</span></code></pre></div><p>As most of my exposed services <em>should</em> be behind cloudflare, I decided to apply this directly to the entrypoint (traefik CLI flag)</p>
<pre><code>      - --entrypoints.https_external.http.tls.options=cfcert@file
</code></pre><p>This makes it the default <code>tls.option</code> for any service on entrypoint <code>https_external</code> üëç<br>
And to disable it, just need to apply label <code>traefik.http.routers.myweb_ext.tls.options: &quot;default&quot;</code> to a service.</p>
<p><em>NOTE</em></p>
<p><em>For some reason a label such as <code>traefik.http.routers.myweb_ext.tls: &quot;true&quot;</code> resets everything in <code>tls</code> back to default. Remove it if you don&rsquo;t need (it should be implicit anyway). If you do need, just re-define <code>tls.options</code> as well.</em></p>
<p>Unfortunately, setting the <code>tls.option</code> at entrypoint level still does not apply to the default router (the 404 shown when no service matches), and I&rsquo;d really like to have traefik just TLS-reset all those botscan connections&hellip;</p>
<p>I tried modifying <code>default</code> <code>tls.options</code> (instead of naming it <code>cfcert</code>) but then it applied to every entrypoint, including the internal ones (which hopefully are never pinged by cloudflare!).</p>
<p>Also found <a href="https://www.techjunktrunk.com/docker/2017/11/03/traefik-default-server-catch-all/">this</a> to setup a new default service. It seems to work as advertised, matching any request that was not caught by others, but:</p>
<pre><code>traefik_traefik.1.lqdaryaciaex@sfpi3    | time=&quot;2021-04-09T00:02:07Z&quot; level=warning msg=&quot;No domain found in rule HostRegexp(`{catchall:.*}`), the TLS options applied for this router will depend on the hostSNI of each request&quot; entryPointName=https_external routerName=myweb_ext@docker
</code></pre><p>So traefik only binds tls.options based on the configured SNI, not in the SNI requested&hellip;</p>
<p>Too bad, but still happy overall with the final setup!</p>
<p>Fun part: I finally did this last week and today cloudflare announced <a href="https://www.cloudflare.com/ips/">IP changes</a>. But no, I don&rsquo;t have to do anything about it (anymore).</p>
]]></content></item><item><title>0x474E (In)fluent(a)bit</title><link>https://rpg.skmobi.com/posts/0x474e_telegraf/</link><pubDate>Mon, 01 Mar 2021 00:16:05 +0000</pubDate><guid>https://rpg.skmobi.com/posts/0x474e_telegraf/</guid><description>I&amp;rsquo;ve moved log collection and telemetry out of GCP Stackdriver (mentioned before) to on-prem InfluxDB (running in a raspberry pi 4 4GB)
FluentBit was the agent of choice at the time but Telegraf seemed like a good candidate now.
Why fluentd has a lot of plugins but its crappy ruby codebase eats way too many resources for me (why would anyone?) to use it.
Luckily, the same guys gave it an extreme makeover in C and called it fluentbit.</description><content type="html"><![CDATA[<p>I&rsquo;ve moved log collection and telemetry out of GCP Stackdriver (mentioned <a href="/tags/gcp/">before</a>) to on-prem <a href="https://www.influxdata.com">InfluxDB</a> (running in a raspberry pi 4 4GB)</p>
<p>FluentBit was the agent of choice at the time but <a href="https://www.influxdata.com/time-series-platform/telegraf/">Telegraf</a> seemed like a good candidate now.</p>
<h2 id="why">Why</h2>
<p><a href="https://www.fluentd.org/">fluentd</a> has a lot of plugins but its crappy ruby codebase eats way too many resources for me (why would anyone?) to use it.<br>
Luckily, the same guys gave it an extreme makeover in C and called it <a href="https://fluentbit.io/">fluentbit</a>. Sadly, its community hasn&rsquo;t grown that much so not so many plugins available out of the box, but making new ones is quite easy: I&rsquo;ve built <a href="https://github.com/fopina/docker-fluent-bit-plugin-dev">this docker image</a> to make it easier to build the plugins and <a href="https://github.com/fopina?tab=repositories&amp;q=fluent-bit">already made a few of my own</a></p>
<p>As <a href="https://www.influxdata.com/time-series-platform/telegraf/">Telegraf</a> is in Go (worse than C but way better than ruby) and it has almost as many plugins available as fluentd, it seemed like a good reason to measure how worse it was resource-wise (than fluentbit) to be able to weight it properly.</p>
<h2 id="how">How</h2>
<h3 id="tldr">TL;DR;</h3>
<ul>
<li>setup telegraf and fluentbit collecting the same metrics: memory, cpu and disk IO</li>
<li>setup a second telegraf to monitor those two agents (with <a href="https://github.com/influxdata/telegraf/blob/master/plugins/inputs/procstat/README.md">procstat</a>)</li>
<li>compare baseline telemetry data to make sure they do the same</li>
<li>compare telemetry data of the collector processes to weight telegraf resource-hogging</li>
</ul>
<h3 id="test-details">Test Details</h3>
<p>Test hardware: raspberry pi 2</p>
<p>All telemetry data goes to an influxdb 2.0.4 instance</p>
<ul>
<li>download telegraf</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">curl -LO https://dl.influxdata.com/telegraf/releases/telegraf-1.17.2_linux_armhf.tar.gz
</code></pre></div><ul>
<li>
<p>create test buckets</p>
<ul>
<li>test_telegraf</li>
<li>test_fluentbit</li>
<li>test_results</li>
</ul>
</li>
<li>
<p>install fluentbit</p>
</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">curl https://packages.fluentbit.io/fluentbit.key <span class="p">|</span> sudo apt-key add -
<span class="nb">echo</span> deb https://packages.fluentbit.io/debian/buster buster main &gt; /etc/apt/sources.list.d/fluentbit.list
apt update
apt install td-agent-bit
</code></pre></div><ul>
<li>telegraf configuration</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-toml" data-lang="toml"><span class="p">[</span><span class="nx">agent</span><span class="p">]</span>
  <span class="nx">interval</span> <span class="p">=</span> <span class="s2">&#34;10s&#34;</span>
  <span class="nx">round_interval</span> <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">metric_batch_size</span> <span class="p">=</span> <span class="mi">1000</span>
  <span class="nx">metric_buffer_limit</span> <span class="p">=</span> <span class="mi">10000</span>
  <span class="nx">collection_jitter</span> <span class="p">=</span> <span class="s2">&#34;0s&#34;</span>
  <span class="nx">flush_interval</span> <span class="p">=</span> <span class="s2">&#34;10s&#34;</span>
  <span class="nx">flush_jitter</span> <span class="p">=</span> <span class="s2">&#34;0s&#34;</span>
  <span class="nx">precision</span> <span class="p">=</span> <span class="s2">&#34;&#34;</span>
  <span class="nx">debug</span> <span class="p">=</span> <span class="kc">false</span>
  <span class="nx">quiet</span> <span class="p">=</span> <span class="kc">false</span>
  <span class="nx">logfile</span> <span class="p">=</span> <span class="s2">&#34;&#34;</span>
  <span class="nx">hostname</span> <span class="p">=</span> <span class="s2">&#34;&#34;</span>
  <span class="nx">omit_hostname</span> <span class="p">=</span> <span class="kc">false</span>
<span class="p">[[</span><span class="nx">outputs</span><span class="p">.</span><span class="nx">influxdb_v2</span><span class="p">]]</span>
  <span class="nx">urls</span> <span class="p">=</span> <span class="p">[</span><span class="s2">&#34;https://my.influxdb&#34;</span><span class="p">]</span>
  <span class="nx">token</span> <span class="p">=</span> <span class="s2">&#34;&lt;TOKEN&gt;&#34;</span>
  <span class="nx">organization</span> <span class="p">=</span> <span class="s2">&#34;myorg&#34;</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">&#34;test_telegraf&#34;</span>
<span class="p">[[</span><span class="nx">inputs</span><span class="p">.</span><span class="nx">cpu</span><span class="p">]]</span>
  <span class="nx">percpu</span> <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">totalcpu</span> <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">collect_cpu_time</span> <span class="p">=</span> <span class="kc">false</span>
  <span class="nx">report_active</span> <span class="p">=</span> <span class="kc">false</span>
<span class="p">[[</span><span class="nx">inputs</span><span class="p">.</span><span class="nx">diskio</span><span class="p">]]</span>
<span class="p">[[</span><span class="nx">inputs</span><span class="p">.</span><span class="nx">mem</span><span class="p">]]</span>
</code></pre></div><ul>
<li>start telegraf</li>
</ul>
<pre><code>telegraf-1.17.2/usr/bin/telegraf --config telegraf.conf
</code></pre><ul>
<li>fluentbit configuration</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-ini" data-lang="ini"><span class="k">[SERVICE]</span>
    <span class="na">Flush        5</span>
    <span class="na">Daemon       Off</span>
    <span class="na">Log_Level    info</span>
    <span class="na">HTTP_Server  Off</span>
    <span class="na">Plugins_File /etc/td-agent-bit/plugins.conf</span>
<span class="k">[INPUT]</span>
    <span class="na">Name cpu</span>
    <span class="na">Tag met.cpu</span>
<span class="k">[INPUT]</span>
    <span class="na">Name mem</span>
    <span class="na">Tag met.mem</span>
<span class="k">[INPUT]</span>
    <span class="na">Name disk</span>
    <span class="na">Tag met.disk</span>
<span class="k">[FILTER]</span>
    <span class="na">Name record_modifier</span>
    <span class="na">Match *</span>
    <span class="na">Record hostname ${HOSTNAME}</span>
<span class="k">[OUTPUT]</span>
    <span class="na">Name influxdb_v2</span>
    <span class="na">Match met.*</span>
    <span class="na">Host my.influx</span>
    <span class="na">Port 443</span>
    <span class="na">tls on</span>
    <span class="na">tls.verify off</span>
    <span class="na">org myorg</span>
    <span class="na">bucket test_fluentbit</span>
    <span class="na">http_token &lt;TOKEN&gt;</span>
    <span class="na">Tag_Keys hostname</span>
</code></pre></div><ul>
<li>start fluentbit</li>
</ul>
<pre><code>/opt/td-agent-bit/bin/td-agent-bit -c fluentbit.conf
</code></pre><ul>
<li>configuration to monitor agents (using telegraf)</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-toml" data-lang="toml"><span class="p">[</span><span class="nx">agent</span><span class="p">]</span>
  <span class="nx">interval</span> <span class="p">=</span> <span class="s2">&#34;10s&#34;</span>
  <span class="nx">round_interval</span> <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">metric_batch_size</span> <span class="p">=</span> <span class="mi">1000</span>
  <span class="nx">metric_buffer_limit</span> <span class="p">=</span> <span class="mi">10000</span>
  <span class="nx">collection_jitter</span> <span class="p">=</span> <span class="s2">&#34;0s&#34;</span>
  <span class="nx">flush_interval</span> <span class="p">=</span> <span class="s2">&#34;10s&#34;</span>
  <span class="nx">flush_jitter</span> <span class="p">=</span> <span class="s2">&#34;0s&#34;</span>
  <span class="nx">precision</span> <span class="p">=</span> <span class="s2">&#34;&#34;</span>
  <span class="nx">debug</span> <span class="p">=</span> <span class="kc">false</span>
  <span class="nx">quiet</span> <span class="p">=</span> <span class="kc">false</span>
  <span class="nx">logfile</span> <span class="p">=</span> <span class="s2">&#34;&#34;</span>
  <span class="nx">hostname</span> <span class="p">=</span> <span class="s2">&#34;&#34;</span>
  <span class="nx">omit_hostname</span> <span class="p">=</span> <span class="kc">false</span>
<span class="p">[[</span><span class="nx">outputs</span><span class="p">.</span><span class="nx">influxdb_v2</span><span class="p">]]</span>
  <span class="nx">urls</span> <span class="p">=</span> <span class="p">[</span><span class="s2">&#34;https://my.influxdb&#34;</span><span class="p">]</span>
  <span class="nx">token</span> <span class="p">=</span> <span class="s2">&#34;&lt;TOKEN&gt;&#34;</span>
  <span class="nx">organization</span> <span class="p">=</span> <span class="s2">&#34;myorg&#34;</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">&#34;test_results&#34;</span>
<span class="p">[[</span><span class="nx">inputs</span><span class="p">.</span><span class="nx">procstat</span><span class="p">]]</span>
  <span class="nx">pattern</span> <span class="p">=</span> <span class="s2">&#34;/opt/td-agent-bit/bin/td-agent-bit -c fluentbit.conf&#34;</span>
<span class="p">[[</span><span class="nx">inputs</span><span class="p">.</span><span class="nx">procstat</span><span class="p">]]</span>
  <span class="nx">pattern</span> <span class="p">=</span> <span class="s2">&#34;telegraf-1.17.2/usr/bin/telegraf --config telegraf.conf&#34;</span>
</code></pre></div><ul>
<li>start second telegraf (agent monitor)</li>
</ul>
<pre><code>telegraf-1.17.2/usr/bin/telegraf --config telemon.conf
</code></pre><h2 id="results">Results</h2>
<p>Left this running for over a week and these were the results:</p>







<a href="/posts/0x474e_telegraf/telemetry.png">
    <img src="/posts/0x474e_telegraf/telemetry_hu6c23431beb74cea6008f6c754aa6e6d6_211171_600x0_resize_box_2.png" width="600" height="154">
</a>

<p>Both lines (from fluentbit and telegraf) basically match so they produced identical telemetry data. Exception <em>might</em> be disk IO where they use different units and I didn&rsquo;t bother to find out how to convert üèùÔ∏è</p>
<p>And the results that matter: fluentbit process telemetry versus telegraf</p>







<a href="/posts/0x474e_telegraf/versus.png">
    <img src="/posts/0x474e_telegraf/versus_hu170fd6466c940eb28572d2fc65907ba2_239151_600x0_resize_box_2.png" width="600" height="132">
</a>

<h3 id="cpu">CPU</h3>
<p>fluentbit (blue line) at 0.4% and telegraf between 0.6% and 0.7%.<br>
we can also see the frequent ups and downs that probably come with any garbage-collected language versus the the flat(ter) line of fluentbit and its finetuned malloc and free timings.</p>
<h3 id="mem">MEM</h3>
<p>fluentbit (blue line) uses around 10mb of memory (1% in this RPi 2) and telegraf uses between 20mb and 40mb.</p>
<h3 id="disk-io">Disk IO</h3>
<p>fluentbit read count (blue line) increases much faster than telegraf&rsquo;s (red line), yet write count lines are basically the same. Not entirely sure what this means though.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Fluentbit has a long way to go in plugin availiability and even much longer way for Windows targets&hellip; So if I had Windows machines or I needed a specific plugin and could not build it myself, I think telegraf resource usage wouldn&rsquo;t be an issue.</p>
<p>But as I already have fluentbit setup for my own plugins, if I need any out of the core ones, I&rsquo;ll keep fluentbit for the smaller footprint.</p>
]]></content></item><item><title>0x6FD7 docker images and internal CAs</title><link>https://rpg.skmobi.com/posts/0x6fd7_docker_internal_ca/</link><pubDate>Mon, 15 Feb 2021 01:13:47 +0000</pubDate><guid>https://rpg.skmobi.com/posts/0x6fd7_docker_internal_ca/</guid><description>I use an internal CA for all the services in my home lab.
Big part of the lab is running on docker swarm.
Usually services connect through internal networks (without using HTTPS as that is offloaded to traefik), but sometimes they do need to validate the certificates (such as interacting with the NAS or router APIs).
For personal images, private CA is naturally bundled into them.
For public, 3rd party, ones, I usually rebuild them only for that purpose, such as:</description><content type="html"><![CDATA[<p>I use an internal CA for all the services in my home lab.<br>
Big part of the lab is running on docker swarm.<br>
Usually services connect through internal networks (without using HTTPS as that is offloaded to traefik), but sometimes they do need to validate the certificates (such as interacting with the NAS or router APIs).</p>
<p>For personal images, private CA is naturally bundled into them.<br>
For public, 3rd party, ones, I usually rebuild them only for that purpose, such as:</p>
<div class="highlight"><pre class="chroma"><code class="language-dockerfile" data-lang="dockerfile"><span class="k">FROM</span><span class="s"> homeassistant/home-assistant:2021.2.3</span><span class="err">
</span><span class="err">
</span><span class="err"></span><span class="k">ADD</span> myCA.pem /usr/local/share/ca-certificates/myCA.crt<span class="err">
</span><span class="err"></span><span class="k">RUN</span> /usr/sbin/update-ca-certificates<span class="err">
</span><span class="err"></span><span class="c"># for python requests lib...</span><span class="err">
</span><span class="err"></span><span class="k">ENV</span> <span class="nv">REQUESTS_CA_BUNDLE</span><span class="o">=</span>/etc/ssl/certs/ca-certificates.crt<span class="err">
</span></code></pre></div><p>This means that everytime the upstream image is updated, I have to rebuild it (before re-deploy). Pain&hellip;</p>
<p>Much simpler option is to bind mount the host trusted certificates in the container (assuming host has the CA setup).</p>
<p>My raspberry Pis (the swarm cluster) have the CA installed with:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="l">(tasks - for debian/raspbian)</span><span class="w">
</span><span class="w"></span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">copy my CA</span><span class="w">
</span><span class="w">  </span><span class="nt">copy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">src</span><span class="p">:</span><span class="w"> </span><span class="l">myCA.pem</span><span class="w">
</span><span class="w">    </span><span class="nt">dest</span><span class="p">:</span><span class="w"> </span><span class="l">/usr/local/share/ca-certificates/myCA.crt</span><span class="w">
</span><span class="w">    </span><span class="nt">owner</span><span class="p">:</span><span class="w"> </span><span class="l">root</span><span class="w">
</span><span class="w">    </span><span class="nt">group</span><span class="p">:</span><span class="w"> </span><span class="l">root</span><span class="w">
</span><span class="w">    </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="m">0644</span><span class="w">
</span><span class="w">  </span><span class="nt">become</span><span class="p">:</span><span class="w"> </span><span class="kc">True</span><span class="w">
</span><span class="w">  </span><span class="nt">notify</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="l">update trusted ca</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="l">(handlers)</span><span class="w">
</span><span class="w"></span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">update trusted ca</span><span class="w">
</span><span class="w">  </span><span class="nt">shell</span><span class="p">:</span><span class="w"> </span><span class="l">/usr/sbin/update-ca-certificates</span><span class="w">
</span><span class="w">  </span><span class="nt">become</span><span class="p">:</span><span class="w"> </span><span class="kc">True</span><span class="w">
</span></code></pre></div><p>So any containers running in these hosts can have the system trusted CAs (including internal one) bind mounted with:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">docker run -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt:ro <span class="se">\
</span><span class="se"></span>           -e <span class="nv">REQUESTS_CA_BUNDLE</span><span class="o">=</span>/etc/ssl/certs/ca-certificates.crt <span class="se">\
</span><span class="se"></span>           homeassistant/home-assistant:2021.2.3
</code></pre></div>]]></content></item><item><title>0xB752 ddwrt + custom certificate</title><link>https://rpg.skmobi.com/posts/0xb752_ddwrt_ssl/</link><pubDate>Sun, 14 Feb 2021 16:26:09 +0000</pubDate><guid>https://rpg.skmobi.com/posts/0xb752_ddwrt_ssl/</guid><description>When I first installed dd-wrt (no support from openwrt) on my router, I enabled HTTPS-only access for the web UI.
When the nasty prompt from the self-signed certificate popped up, I looked for an option to upload my own cerficate (signed by the internal CA I use).
There was none&amp;hellip;
Left it be for quite soem time, but finally decided to sort it out and, to my surprise, there&amp;rsquo;s no official documentation on it (or not easy to find, at least)&amp;hellip;</description><content type="html"><![CDATA[<p>When I first installed <a href="https://dd-wrt.com/">dd-wrt</a> (no support from <a href="https://openwrt.org/">openwrt</a>) on <a href="https://www.netgear.com/home/online-gaming/routers/xr500/">my router</a>, I enabled HTTPS-only access for the web UI.<br>
When the nasty prompt from the self-signed certificate popped up, I looked for an option to upload my own cerficate (signed by the internal CA I use).<br>
There was none&hellip;</p>
<p>Left it be for quite soem time, but finally decided to sort it out and, to my surprise, there&rsquo;s no official documentation on it (or not easy to find, at least)&hellip;</p>
<p>Found <a href="https://forum.dd-wrt.com/phpBB2/viewtopic.php?t=27979">this thread</a> on their forum which basically set two options:</p>
<ul>
<li>using <a href="https://forum.dd-wrt.com/wiki/index.php/Development#Firmware_Modification_Kit">firmware mod kit</a> to embed your cert into the image before flashing (no need to recompile at least&hellip;)</li>
<li>enable JFFS, save the cert (and key) there and use a startup script to <code>mount -o bind</code> those on the default <code>/etc/cert.pem</code> and <code>/etc/key.pem</code> locations</li>
</ul>
<p>I found it hard to believe that dd-wrt had no GUI setting for a custom SSL cert, even more that there wouldn&rsquo;t be some <code>nvram</code> setting to store one, at least using ssh&hellip;</p>
<p>Both options would be ok, but I decided to take a quick look at dd-wrt code and found <a href="https://github.com/mirror/dd-wrt/blob/088ba261dfe84e43e5954dd66e9ced02c01a1a95/src/router/httpd/httpd.c#L1564-L1583">this</a>:</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="cp">#if defined(HAVE_OPENSSL) || defined(HAVE_MATRIXSSL) || defined(HAVE_POLARSSL)
</span><span class="cp"></span>		<span class="kt">char</span> <span class="o">*</span><span class="n">cert</span> <span class="o">=</span> <span class="n">nvram_safe_get</span><span class="p">(</span><span class="s">&#34;https_cert&#34;</span><span class="p">);</span>
		<span class="kt">char</span> <span class="o">*</span><span class="n">key</span> <span class="o">=</span> <span class="n">nvram_safe_get</span><span class="p">(</span><span class="s">&#34;https_key&#34;</span><span class="p">);</span>
		<span class="kt">char</span> <span class="o">*</span><span class="n">certfile</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
		<span class="kt">char</span> <span class="o">*</span><span class="n">keyfile</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">*</span><span class="n">cert</span><span class="p">)</span> <span class="p">{</span>
			<span class="n">certfile</span> <span class="o">=</span> <span class="s">&#34;/tmp/https_cert&#34;</span><span class="p">;</span>
			<span class="n">writenvram</span><span class="p">(</span><span class="s">&#34;https_cert&#34;</span><span class="p">,</span> <span class="n">certfile</span><span class="p">);</span>
		<span class="p">}</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">*</span><span class="n">key</span><span class="p">)</span> <span class="p">{</span>
			<span class="n">keyfile</span> <span class="o">=</span> <span class="s">&#34;/tmp/https_key&#34;</span><span class="p">;</span>
			<span class="n">writenvram</span><span class="p">(</span><span class="s">&#34;https_key&#34;</span><span class="p">,</span> <span class="n">keyfile</span><span class="p">);</span>
		<span class="p">}</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">certfile</span><span class="p">)</span>
			<span class="n">certfile</span> <span class="o">=</span> <span class="n">nvram_safe_get</span><span class="p">(</span><span class="s">&#34;https_cert_file&#34;</span><span class="p">);</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!*</span><span class="n">certfile</span><span class="p">)</span>
			<span class="n">certfile</span> <span class="o">=</span> <span class="n">CERT_FILE</span><span class="p">;</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">keyfile</span><span class="p">)</span>
			<span class="n">keyfile</span> <span class="o">=</span> <span class="n">nvram_safe_get</span><span class="p">(</span><span class="s">&#34;https_key_file&#34;</span><span class="p">);</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!*</span><span class="n">keyfile</span><span class="p">)</span>
			<span class="n">keyfile</span> <span class="o">=</span> <span class="n">KEY_FILE</span><span class="p">;</span>
<span class="cp">#endif
</span></code></pre></div><p>Taking a look at blame it points to <a href="https://github.com/mirror/dd-wrt/commit/e27ffb50f592a58a392c789a24e2e681eb298112">rev 44703</a>, so sort of recent.</p>
<p>It seems before it already supported specifying a custom location but only if was compiled with <code>HAVE_CUSTOMSSLCERT</code> ü§∑</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="cp">#ifdef HAVE_CUSTOMSSLCERT
</span><span class="cp"></span>		<span class="k">if</span> <span class="p">(</span><span class="n">SSL_CTX_use_certificate_file</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">certfile</span><span class="p">,</span> <span class="n">SSL_FILETYPE_PEM</span><span class="p">)</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">SSL_CTX_use_certificate_file</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">nvram_safe_get</span><span class="p">(</span><span class="s">&#34;https_cert_file&#34;</span><span class="p">),</span> <span class="n">SSL_FILETYPE_PEM</span><span class="p">)</span>
<span class="cp">#else
</span><span class="cp"></span>		<span class="k">if</span> <span class="p">(</span><span class="n">SSL_CTX_use_certificate_file</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">CERT_FILE</span><span class="p">,</span> <span class="n">SSL_FILETYPE_PEM</span><span class="p">)</span>
<span class="cp">#endif
</span></code></pre></div><p>Anyway, I haven&rsquo;t found these new nvram settings documented anywhere, so I&rsquo;ll highlight them here:</p>
<ul>
<li><code>https_cert</code> / <code>https_key</code> - set them to the raw content of a cert / key and done, no need to store them anywhere in the router filesystem (so it does not require JFFS enabled)</li>
<li><code>https_cert_file</code> / <code>https_key_file</code> - set them to the paths to each respective file, so you&rsquo;ll have to enable JFFS (or embed in the image, though that wouldn&rsquo;t make much sense - just overwrite the default one). I assume this might be helpful if <a href="https://letsencrypt.org/">Let&rsquo;s Encrypt</a> (or any other form of short-lived certs) are used and it&rsquo;s easier to replace a file that push to <code>nvram</code>. Or maybe if a very long chain of trust is used in the cert&hellip;?</li>
</ul>
<p>I went with the cleanest option of putting cert and key directly in <code>nvram</code>:</p>
<ul>
<li>generate certificate with <a href="https://github.com/jsha/minica">minica</a></li>
</ul>
<pre><code>minica -ca-cert .. -ca-key .. -domains myrouter.internal -ip-addresses 192.168.1.1
</code></pre><ul>
<li>ssh to router and set the <code>nvram</code> keys:</li>
</ul>
<pre><code>$ nvram set https_cert='-----BEGIN CERTIFICATE-----
...
-----END CERTIFICATE-----'
$ nvram set https_key='-----BEGIN RSA PRIVATE KEY-----
...
-----END RSA PRIVATE KEY-----
</code></pre><ul>
<li>reload web UI</li>
</ul>
<pre><code>$ stopservice httpd
$ startservice httpd
</code></pre>]]></content></item><item><title>0xF404 Mono Price, Mini Print</title><link>https://rpg.skmobi.com/posts/0xf404_mini_delta/</link><pubDate>Wed, 09 Dec 2020 23:38:59 +0000</pubDate><guid>https://rpg.skmobi.com/posts/0xf404_mini_delta/</guid><description>TL;DR; One year ago I bought a MP Mini Delta, my final review:
Pros:
Cheapest I could find - bought it ¬£91 Really compact - perk of the delta style and the very small print bed, fits perfectly in a normal desk corner, no need for huge workbenches like most of the others Sturdy, portable - sturdy build and an handle makes it easy and trouble-free to move around Heated bed - rare in cheap printers Cons:</description><content type="html"><![CDATA[<h2 id="tldr">TL;DR;</h2>
<p>One year ago I bought a <a href="https://www.monoprice.uk/collections/3d-printers/products/monoprice-mp-mini-delta-3d-printer">MP Mini Delta</a>, my final review:</p>
<p>Pros:</p>
<ul>
<li><em>Cheapest I could find</em> - bought it ¬£91</li>
<li><em>Really compact</em> - perk of the <a href="https://3dinsider.com/what-is-a-delta-3d-printer/">delta</a> style and the very small print bed, fits perfectly in a normal desk corner, no need for huge workbenches like most of the others</li>
<li><em>Sturdy, portable</em> - sturdy build and an handle makes it easy and trouble-free to move around</li>
<li><em>Heated bed</em> - rare in cheap printers</li>
</ul>
<p>Cons:</p>
<ul>
<li><em>WiFi</em> - should be a <em>PRO</em> as it is uncommon in cheap printers, but it simply doesn&rsquo;t work</li>
<li><em>Print bed</em> - 11cm <em>diameter</em> is quite small</li>
<li><em>Support</em> - it&rsquo;s just ridiculous how bad it is</li>
</ul>
<h2 id="the-search">The Search</h2>
<p>One year I decided it was time to get a 3d printer.<br>
In a previous company I had to <a href="https://www.openscad.org/">prototype</a> a few boxes and printed them on a <a href="https://shop.beeverycreative.com/produto/beethefirstplus/">Bee</a>.<br>
When I moved into a new job, there was a <a href="https://www.anet3d.com/product/a8-plus-diy/">Anet A8</a> to play but a lot of people used it and left it broken.</p>
<p>As 3d printers were becoming cheaper and cheaper I decided it was time to look for one, though it had to:</p>
<ul>
<li>cheap - not serious into 3d printing</li>
<li>compact - not too much space in my apartment home office</li>
</ul>
<p>I wouldn&rsquo;t mind if it was complex to setup and maintain as long as it paid off for flexibility (eg: extruders for different materials) or other benefits, but it definitely had to be smaller than <em>Anet A8</em></p>
<p>Then I found <a href="https://www.monoprice.uk/collections/3d-printers/products/monoprice-mp-mini-delta-3d-printer">MP Mini Delta</a>.</p>
<ul>
<li>Cheap  ‚úÖ - seriously couldn&rsquo;t find anything cheaper&hellip;</li>
<li>Compact ‚úÖ - small yet everything well protected inside a sturdy steel build</li>
<li>Ready to use - unexpected but nice!</li>
</ul>
<p>I also read <code>11cm</code> for the print bed but missed the <em>circular</em>, so I thought it was a perfect size for raspberry pi cases and all&hellip; (but wrong ‚ùå)</p>
<p>Promptly ordered it üì¶</p>
<h2 id="first-blood">First Blood</h2>
<p>As soon as I unboxed the printer, I admit, I was positevely surprised by the looks of it.</p>
<p>Pulled out the manual, inserted the SD card that comes with it and in less than 10 minutes after unboxing (<em>literally</em>) it was printing out the test <a href="https://en.wikipedia.org/wiki/Maneki-neko">maneki-neko</a>.<br>
Definitely amazed how simple and fast it was.</p>
<p>A little over 2h after, the print was done and quality was quite decent (much better than expected).</p>
<p>First setback though, finally noticed that print bed had <code>11cm</code> of <em>diameter</em>, not square size. That means only a square of <code>7.7cm</code> is possible, quite the difference&hellip; Oh well.</p>
<h2 id="pull-back">Pull Back</h2>
<p>Now that the print test was done, I needed to print something of mine to see how it worked out.</p>
<p>The SD card had the <code>.gcode</code> for the maneki-neko, an installer of <code>Cura 15.04.6</code>, Cura profile settings for the printer and digital version of the manual. Whole content backed up (and shared) <a href="https://github.com/fopina/mp-mini-delta-cura/tree/main/original-but-old">here</a>.</p>
<p>But no Mac version. Googling a bit <code>Cura 15</code> was a legacy version, it was now <a href="https://ultimaker.com/software/ultimaker-cura">Ultimaker Cura</a> and new version scheme.<br>
So I download that one. Surprise, USB printing had been removed.</p>
<p>But WiFi printing is supported. I saw WiFi mentioned in the manual, let&rsquo;s set it up!<br>
The manual says to download <code>MP 3D Printer WiFi Connect</code> app from Play Store or iTunes, but no direct links.<br>
I look them up, nothing. There was only an app called <code>MP Mini 3D Printer Client &amp; Connect.</code> (but no longer available either today) but it was from random individual (later found out he was part of the <a href="https://www.mpminidelta.com/">MP community</a>) not from Monoprice. And only for Android.</p>
<p>So I drop them an email:</p>
<blockquote>
<p>From: me<br>
Received: Thu Nov 14 2019 16:35:16 GMT-0800 (Pacific Standard Time)<br>
To: <a href="mailto:tech@monoprice.com">tech@monoprice.com</a>; Technical Support;<br>
Subject: wifi connect mobile app</p>
<p>Hello, where can I find the mobile apps for wifi connection? Android or iOS, I cannot find either&hellip;</p>
</blockquote>
<p>I get this reply:</p>
<blockquote>
<p>From: Tech <a href="mailto:Tech@monoprice.com">Tech@monoprice.com</a><br>
Nov 15, 2019, 5:26 PM</p>
<p>Good Morning!<br>
What I would suggest is go to Google Play Store on an Android device. Search &ldquo;MP 3D Printer Wifi Connect&rdquo; one of the first options after searching should be &ldquo;MP Mini 3D Printer Client &amp; Connect.&rdquo; Download that program and follow the instructions. There is also instructions inside the manual for the MP Mini Delta 3D  Printer. If you don&rsquo;t have the manual on hand you can go to the Monoprice website search the printer, at the bottom of the printer product page is a link to the Manual. If you have any other questions or need any help I am more than happy to help out. Have a great day!</p>
</blockquote>
<p>I reply that I had done it but it wasn&rsquo;t the official app, so they say:</p>
<blockquote>
<p>From: Tech <a href="mailto:Tech@monoprice.com">Tech@monoprice.com</a><br>
Nov 15, 2019, 7:14 PM</p>
<p>Thank you for the additional information. I am new and it was brought to my attention that that particular program is not an official app, I&rsquo;m sorry for suggesting that one. Unfortunately the best we could do is suggest you go to the Wiki community page that it sounds like you already went to and follow their tutorials, besides that we can&rsquo;t assist with the Wifi connection because we don&rsquo;t currently have any official applications or guides to assist with. Just in case we are talking about two different websites I will provide the link to the Wiki page we always suggest. Outside of that I do want to make sure that it is known that our 3D Printers all only work off a 2.4ghz Wifi signal, so the first thing I would do is make sure you are trying to connect to a 2.4ghz Wifi signal. If I can assist in any other way, please E-mail me back. Have a great day!
MP Mini Delta 3D Printer wiki page: <a href="https://www.mpminidelta.com/">https://www.mpminidelta.com/</a></p>
</blockquote>
<p>So the official support reply for a standard feature not working is to get support from community&hellip; ü§¶</p>
<p>I follow community instructions for <a href="https://www.mpminidelta.com/wifi/g-code_file">connecting to WiFi</a> (.gcode mirrored <a href="https://github.com/fopina/mp-mini-delta-cura/blob/main/original-but-old/wifi_setup.gcode">here</a>) and I can open the printer webpage from my laptop.</p>
<p>Great, so I thought. Trying to add <code>network printer</code> in Cura simply fails all the time, so I take the <a href="https://github.com/fopina/mp-mini-delta-cura/blob/main/original-but-old/auto00-demoCAT.g">test cat .gcode</a> and upload it directly from the browser. I&rsquo;d still be pratical if I could just load the prints that way (after slicing in Cura).<br>
But no, at 9% upload, every time, printer stops responding and only turning it off and back on makes it reponsive again&hellip; Tried another (smaller) .gcode and same&hellip;</p>
<p>I ping the support again</p>
<blockquote>
<p>Understood, just to confirm you are running the printer on a 2.4ghz Wifi correct? The SD card should only have the gcode file on it, if it has anything else you might want to clear it out. As per it failing, even when the Wifi setup is working correct there is always a chance that a file will fail when trying to upload a file through Wifi. From our experience we&rsquo;ve notice that SD card printing is much more reliable than Wifi printing as there are no issues with file transfer. SD card has the best resolution over Wifi and USB. Wifi at best is finicky on transferring files over to the SD card and can experience lag drops. If you have any other questions please E-mail me back.</p>
</blockquote>
<p>Again, printer supports WiFi officially but <code>it's flaky and you should use SD card (not even USB)</code>&hellip;</p>
<h2 id="octoprint">Octoprint</h2>
<p>Gave up on WiFi.</p>
<p>Every 3D print search eventually goes through some <a href="https://octoprint.org/">octoprint</a> link. As I already had a few Pis up and running (as a docker swarm cluster), I decide to plug the printer into one and try it (and built <a href="https://github.com/fopina/docker-octoprint">this docker image</a> to use it)</p>
<p>The USB device is detected but every time I click connect it fails. Google leads me to <a href="https://mpminidelta.com/octoprint/serial_double_open_plugin">this plugin</a>, specifically to solve this issue in these models&hellip;<br>
And finally, I can print the damn cat without the SD card.</p>
<h2 id="slicing">Slicing</h2>
<p>Back to Cura to generate some .gcode by myself (can&rsquo;t print the cat in a loop), the printer is not part of the default profiles. And the profile in the SD card (for <code>Cura 15.04.6</code>) is not compatible.</p>
<p>Reaching out to community again, a facebook group maintains <a href="https://www.mpminidelta.com/slicers/cura">a profile</a>.<br>
I set it up, draw a cube in OpenSCAD, slice up the .STL with this profile, load the .gcode in OctoPrint and happily see it print with success.</p>
<p>Currently, this profile (from the MPMD Facebook group) has been added to <a href="https://github.com/Ultimaker/Cura/blob/master/resources/definitions/mp_mini_delta.def.json">Cura source tree</a>, so installing profile separately is no longer required!</p>
<h2 id="redemption">Redemption</h2>
<p>At some point, I had some warped prints and reached out to support again. They suggeted using <a href="https://github.com/fopina/mp-mini-delta-cura/blob/main/start_code.gcode">this</a> as <code>Start Gcode</code> in the profile. It did seem to solve the issue.<br>
Not using it anymore, but saving it here in case it happens again.</p>
<h2 id="conclusion">Conclusion</h2>
<p>For the price, I couldn&rsquo;t ask much from the support, but maybe they could state that somewhere, that they don&rsquo;t support their own printer. And I&rsquo;d buy it anyway, after finding out about the small yet strong community.</p>
<p>Apart from the support, print-wise, I&rsquo;m quite happy with it and I strongly recommend it as a <code>cheap, compact, ready-to-use</code> printer, if you have a raspberry pi (or anything else) to use with OctoPrint.</p>
]]></content></item><item><title>0x9B4B Free Telemetry</title><link>https://rpg.skmobi.com/posts/0x9b4b_gcp_metrics/</link><pubDate>Tue, 24 Nov 2020 02:54:26 +0000</pubDate><guid>https://rpg.skmobi.com/posts/0x9b4b_gcp_metrics/</guid><description>Some time ago I wrote about leveraging GCP free tier for log collection. I also started using it for telemetry though I never updated the post with those details.
Since Google refactored their Monitoring away from that crappy StackDriver interface, it&amp;rsquo;s actually quite nice, so might as well write the setup down (up? ‚òÅÔ∏è).
Even though GCP monitoring seems oriented to metrics from GCP services it also allows you to create logs-based metrics.</description><content type="html"><![CDATA[<p>Some time ago I <a href="/posts/0xd755_gcp_logging/">wrote</a> about leveraging GCP free tier for log collection. I also started using it for telemetry though I never updated the post with those details.</p>
<p>Since Google refactored their Monitoring away from that crappy StackDriver interface, it&rsquo;s actually quite nice, so might as well write the setup down (up? ‚òÅÔ∏è).</p>
<p>Even though GCP monitoring seems oriented to metrics from GCP services it also allows you to create <a href="https://cloud.google.com/logging/docs/logs-based-metrics/">logs-based metrics</a>.<br>
This basically allows you to defined rules to extract data points from logs into metrics that can be monitored and alerted on.</p>
<p>First things first: based on <a href="/posts/0xd755_gcp_logging/">that previous post about GCP logging</a>, and assuming you have the setup mentioned there to ship logs to GCP/stackdriver, you can use <a href="https://fluentbit.io/">fluentbit</a> to generate these logs.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">~# /opt/td-agent-bit/bin/td-agent-bit -i mem -o stdout
Fluent Bit v1.5.6

<span class="o">[</span>2020/11/24 01:41:24<span class="o">]</span> <span class="o">[</span> info<span class="o">]</span> <span class="o">[</span>engine<span class="o">]</span> started <span class="o">(</span><span class="nv">pid</span><span class="o">=</span>21309<span class="o">)</span>
<span class="o">[</span>2020/11/24 01:41:24<span class="o">]</span> <span class="o">[</span> info<span class="o">]</span> <span class="o">[</span>storage<span class="o">]</span> <span class="nv">version</span><span class="o">=</span>1.0.5, initializing...
<span class="o">[</span>2020/11/24 01:41:24<span class="o">]</span> <span class="o">[</span> info<span class="o">]</span> <span class="o">[</span>storage<span class="o">]</span> in-memory
<span class="o">[</span>2020/11/24 01:41:24<span class="o">]</span> <span class="o">[</span> info<span class="o">]</span> <span class="o">[</span>storage<span class="o">]</span> normal synchronization mode, checksum disabled, <span class="nv">max_chunks_up</span><span class="o">=</span><span class="m">128</span>
<span class="o">[</span>2020/11/24 01:41:24<span class="o">]</span> <span class="o">[</span> info<span class="o">]</span> <span class="o">[</span>sp<span class="o">]</span> stream processor started
<span class="o">[</span>0<span class="o">]</span> mem.0: <span class="o">[</span>1606182084.325065322, <span class="o">{</span><span class="s2">&#34;Mem.total&#34;</span><span class="o">=</span>&gt;948084, <span class="s2">&#34;Mem.used&#34;</span><span class="o">=</span>&gt;772048, <span class="s2">&#34;Mem.free&#34;</span><span class="o">=</span>&gt;176036, <span class="s2">&#34;Swap.total&#34;</span><span class="o">=</span>&gt;102396, <span class="s2">&#34;Swap.used&#34;</span><span class="o">=</span>&gt;6608, <span class="s2">&#34;Swap.free&#34;</span><span class="o">=</span>&gt;95788<span class="o">}]</span>
<span class="o">[</span>1<span class="o">]</span> mem.0: <span class="o">[</span>1606182085.325055771, <span class="o">{</span><span class="s2">&#34;Mem.total&#34;</span><span class="o">=</span>&gt;948084, <span class="s2">&#34;Mem.used&#34;</span><span class="o">=</span>&gt;772088, <span class="s2">&#34;Mem.free&#34;</span><span class="o">=</span>&gt;175996, <span class="s2">&#34;Swap.total&#34;</span><span class="o">=</span>&gt;102396, <span class="s2">&#34;Swap.used&#34;</span><span class="o">=</span>&gt;6608, <span class="s2">&#34;Swap.free&#34;</span><span class="o">=</span>&gt;95788<span class="o">}]</span>
<span class="o">[</span>2<span class="o">]</span> mem.0: <span class="o">[</span>1606182086.325105700, <span class="o">{</span><span class="s2">&#34;Mem.total&#34;</span><span class="o">=</span>&gt;948084, <span class="s2">&#34;Mem.used&#34;</span><span class="o">=</span>&gt;772904, <span class="s2">&#34;Mem.free&#34;</span><span class="o">=</span>&gt;175180, <span class="s2">&#34;Swap.total&#34;</span><span class="o">=</span>&gt;102396, <span class="s2">&#34;Swap.used&#34;</span><span class="o">=</span>&gt;6608, <span class="s2">&#34;Swap.free&#34;</span><span class="o">=</span>&gt;95788<span class="o">}]</span>
</code></pre></div><p>configuration file <code>/etc/td-agent-bit/td-agent-bit.conf</code> would be updated with something like:</p>
<div class="highlight"><pre class="chroma"><code class="language-ini" data-lang="ini"><span class="na">...</span>

<span class="k">[INPUT]</span>
    <span class="na">Name cpu</span>
    <span class="na">Tag cpu</span>
    <span class="na">Interval_Sec 10</span>

<span class="k">[INPUT]</span>
    <span class="na">Name mem</span>
    <span class="na">Tag mem</span>
    <span class="na">Interval_Sec 10</span>

<span class="na">...</span>

<span class="k">[OUTPUT]</span>
    <span class="na">Name stackdriver</span>
    <span class="na">google_service_credentials /etc/gcreds.json</span>
    <span class="na">Match *</span>
</code></pre></div><p>Logs will then show up in GCP Logs Viewer:</p>







<a href="/posts/0x9b4b_gcp_metrics/shot1.png">
    <img src="/posts/0x9b4b_gcp_metrics/shot1_hu74071fae66812d2454692a91eaf0d9b6_107407_600x0_resize_box_2.png" width="600" height="119">
</a>

<p>As an extra step, as fluentbit <code>mem</code> outputs bytes, GCP does not allow any transformation of the data and visualization with multiple hostnames is friendlier when using percentage (instead of absolute values), I&rsquo;ve created <a href="https://github.com/fopina/fluent-bit-filter-math">a fluenbit math filter</a>.</p>
<div class="highlight"><pre class="chroma"><code class="language-ini" data-lang="ini"><span class="na">...</span>
<span class="k">[INPUT]</span>
    <span class="na">Name mem</span>
    <span class="na">Tag mem</span>
    <span class="na">Interval_Sec 10</span>

<span class="k">[FILTER]</span>
    <span class="na">Name math</span>
    <span class="na">Match mem</span>
    <span class="na">Operation div</span>
    <span class="na">Field Mem.used</span>
    <span class="na">Field Mem.total</span>
    <span class="na">Output_field Mem.usage</span>
<span class="na">...</span>
</code></pre></div><p>This <code>[FILTER]</code> entry will add <code>Mem.usage</code> to the output (which is <code>Mem.used / Mem.total</code>).</p>
<p>In the <code>Logs Viewer</code> you can then click <code>Actions</code>, <code>Create Metric</code> and set it up.</p>







<a href="/posts/0x9b4b_gcp_metrics/shot2.png">
    <img src="/posts/0x9b4b_gcp_metrics/shot2_hud475d487dd79bc8f34550ec4e3280d1a_347900_600x0_resize_box_2.png" width="600" height="252">
</a>

<p>Type <code>counter</code> will just measure the number of log lines for the given query while <code>distribution</code> will extract an actual value from each line (distribution being the right choice here).</p>
<p>Metric setup, it can now be added to a dashboard and/or used as alert source</p>







<a href="/posts/0x9b4b_gcp_metrics/shot3.png">
    <img src="/posts/0x9b4b_gcp_metrics/shot3_hucdb481de5eb74ed37e831e5a9b7d20d0_374560_600x0_resize_box_2.png" width="600" height="320">
</a>

<h3 id="note">Note</h3>
<p>These metrics will count both towards logs and metric ingestion limits. At the moment they are respectively 10GB and 150MB (per month).</p>
<p>I have some exclusion filters on the logs (for frequent lines that noone cares). About 10 hosts shipping logs to this (about 30 docker services) and still hardly go above 3GB used for logs.<br>
Metric ingestion does get to 150MB quickly if we start adding a few&hellip;</p>
]]></content></item><item><title>0xCF53 Remote, Garage Remote</title><link>https://rpg.skmobi.com/posts/0xcf53_rgr/</link><pubDate>Sun, 01 Nov 2020 18:40:57 +0000</pubDate><guid>https://rpg.skmobi.com/posts/0xcf53_rgr/</guid><description>Dr. No Open One of my garage openers stopped working but I kept it in hope one day I&amp;rsquo;d make a learning exercise out of repairing it.
The other day somehow I brought it up in a conversation and it was highlighted that it is common for the push button to wear out, so I opened the case and tested by shorting over the button with a wire.
And the garage door opened (thanks Dad)!</description><content type="html"><![CDATA[<h2 id="dr-no-open">Dr. No Open</h2>
<p>One of my garage openers stopped working but I kept it in hope one day I&rsquo;d make a learning exercise out of repairing it.</p>
<p>The other day somehow I brought it up in a conversation and it was highlighted that it is common for the push button to wear out, so I opened the case and tested by shorting over the button with a wire.<br>
And the garage door opened (thanks Dad)!</p>
<p>






<a href="/posts/0xcf53_rgr/remote_1.jpeg">
    <img src="/posts/0xcf53_rgr/remote_1_hu8ec6b6cc74a9a32ea27ee816486b4937_175217_150x0_resize_q75_box.jpeg#inline" width="150" height="200">
</a>








<a href="/posts/0xcf53_rgr/remote_2.jpeg">
    <img src="/posts/0xcf53_rgr/remote_2_huc3cf7066b61b5fc727fd4db0caade3d6_242171_150x0_resize_q75_box.jpeg#inline" width="150" height="200">
</a>








<a href="/posts/0xcf53_rgr/remote_3.jpeg">
    <img src="/posts/0xcf53_rgr/remote_3_hub05e4f94435c691abe24cf940f219232_206405_150x0_resize_q75_box.jpeg#inline" width="150" height="200">
</a>
</p>
<p>Instead of replacing the push button why not use a raspberry to enable the remote?<br>
Then a webapp could open the garage door?</p>
<blockquote>
<p>Alexa, ask Home Assistant to open garage</p>
</blockquote>
<h2 id="from-stackoverflow-with-love">From StackOverflow With Love</h2>
<p>I have used <a href="https://en.wikipedia.org/wiki/Relay">relay switches</a> in the past to open <a href="https://en.wikipedia.org/wiki/Electromagnetic_lock">maglocks</a> but the loud <em>clack</em> was annoying and mechanical sounded unnecessary.</p>
<p>Picked up a multimeter and measured at the push button:</p>
<ul>
<li>V=10v (opener uses 12v battery)</li>
<li>I=4mA</li>
</ul>
<p>Looking into alternatives considered using a simple transistor but sharing GND between the garage opener (12v) and the raspberry (3v3) didn&rsquo;t sound safe.</p>
<p>Dove into the huge world of ICs (thanks x7!) and, overwhelmed with the options, Google led me exactly to <a href="https://electronics.stackexchange.com/questions/76682/shorting-a-remote-control-pushbutton-with-gpio-and-a-transistor">this post in SO</a>. Should&rsquo;ve started with that&hellip;</p>
<p>An octocoupler, LED on one side, transistor with photosensor on the other side. Two isolated circuits, nice one!</p>
<p>According to <a href="http://www.mosaic-industries.com/embedded-systems/microcontroller-projects/raspberry-pi/gpio-pin-electrical-specifications#rpi-gpio-input-voltage-and-output-current-limitations">this</a>, no more than 16mA should be drawn from an output pin in the GPIO and I had a bunch of 330 ohm resistors:</p>
<ul>
<li><code>3v3 = 330 ohm * I</code> &gt; <code>I = 10 mA</code></li>
</ul>
<p>Open up <a href="https://www.digikey.com/en/products/detail/lite-on-inc/4N25/385762">4N25 datasheet</a>: LED on pins 1 and 2 and emitter and collector on 4 and 5.</p>
<p>Schemed it in <a href="https://www.digikey.pt/schemeit/project/rgr1-cc1bac87b73e494884bbe0246aa2afe0/">Digikey</a>, then plugging the bits into a breadboard and connecting to a <a href="https://www.raspberrypi.org/products/raspberry-pi-zero-w/">Pi 0 WiFi</a>:</p>
<p>






<a href="/posts/0xcf53_rgr/scheme1.png">
    <img src="/posts/0xcf53_rgr/scheme1_hu2b2452184f27a22128abfd49f5d9a7ab_394485_500x0_resize_box_2.png" width="500" height="168">
</a>








<a href="/posts/0xcf53_rgr/basic.jpeg">
    <img src="/posts/0xcf53_rgr/basic_huef0e227d741b1d54e2d60df26055aa77_279911_300x0_resize_q75_box.jpeg" width="300" height="400">
</a>
</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># shell over python, just for fun</span>
<span class="c1"># export pin to userspace</span>
<span class="nb">echo</span> <span class="s2">&#34;18&#34;</span> &gt; /sys/class/gpio/export
<span class="c1"># Sets pin 18 as an output</span>
<span class="nb">echo</span> <span class="s2">&#34;out&#34;</span> &gt; /sys/class/gpio/gpio18/direction
<span class="c1"># &#34;push&#34; the button</span>
<span class="nb">echo</span> <span class="s2">&#34;1&#34;</span> &gt; /sys/class/gpio/gpio18/value
<span class="c1"># for 3 seconds</span>
sleep <span class="m">3</span>
<span class="c1"># release</span>
<span class="nb">echo</span> <span class="s2">&#34;0&#34;</span> &gt; /sys/class/gpio/gpio18/value 
</code></pre></div><p>And Sesame is open.</p>
<h2 id="you-must-live-twice">You Must Live Twice</h2>
<p>All good and simple, but what about feedback? If the garage opener battery is dead, the Pi cannot <em>see</em> it anywhere&hellip;</p>
<p>Let&rsquo;s use a second GPIO pin as input and enable it with the current from the opener!<br>
But the Pi works on 3v and the opener is working on 10v&hellip;<br>
D√©j√† vu, another 4N25 it is then, the other way around: input will be the garage opener and the output will be connecting Pi 3v3 to the input GPIO pin.</p>
<ul>
<li>Updated the scheme in <a href="https://www.digikey.pt/schemeit/project/rgr1-cc1bac87b73e494884bbe0246aa2afe0/b59742577e02417988ec0c8ade0acb29">Digikey</a></li>
</ul>







<a href="/posts/0xcf53_rgr/scheme2.png">
    <img src="/posts/0xcf53_rgr/scheme2_hub59d32c9272cd5a9921cbd512959cabd_239752_500x0_resize_box_2.png" width="500" height="212">
</a>

<ul>
<li>Applied it in the breadboard</li>
</ul>







<a href="/posts/0xcf53_rgr/basic_2.jpeg">
    <img src="/posts/0xcf53_rgr/basic_2_hu67307361ed8a787880e671b3b667181a_289354_300x0_resize_q75_box.jpeg" width="300" height="400">
</a>

<p>And there: enabling GPIO 18 will enable the opener that then enables GPIO 24. If opener battery is dead, it won&rsquo;t trigger the second 4N25, not enabling GPIO 24.</p>
<p>In this setup, there&rsquo;s no GND connected to GPIO 24 so the GPIO setup needs proper <code>pull_up_down</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">GPIO</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">GPIO</span><span class="o">.</span><span class="n">IN</span><span class="p">,</span> <span class="n">pull_up_down</span><span class="o">=</span><span class="n">GPIO</span><span class="o">.</span><span class="n">PUD_DOWN</span><span class="p">)</span>
</code></pre></div><h2 id="pentapussy">Pentapussy</h2>
<p>Time to trim a stripboard and solder!</p>
<p>






<a href="/posts/0xcf53_rgr/penta1.jpeg">
    <img src="/posts/0xcf53_rgr/penta1_hu4839fef8723a485f1eb3e57ecdc2f7d6_162711_0x250_resize_q75_box.jpeg#inline" width="268" height="250">
</a>








<a href="/posts/0xcf53_rgr/penta2.jpeg">
    <img src="/posts/0xcf53_rgr/penta2_hu97d8da35f928ea3ee29bf723c9a864cb_285945_0x250_resize_q75_box.jpeg#inline" width="333" height="250">
</a>
</p>
<p>Nice mess of wires but it ended up small</p>
<table>
<thead>
<tr>
<th>Wire</th>
<th>Pin</th>
</tr>
</thead>
<tbody>
<tr>
<td>Green</td>
<td>Pi GPIO 18</td>
</tr>
<tr>
<td>Blue</td>
<td>Pi GND</td>
</tr>
<tr>
<td>Red</td>
<td>Garage Opener GND</td>
</tr>
<tr>
<td>Brown</td>
<td>Garage Opener Vcc</td>
</tr>
<tr>
<td>Orange</td>
<td>Pi 3v3</td>
</tr>
<tr>
<td>Yellow</td>
<td>Pi GPIO 24</td>
</tr>
</tbody>
</table>
<h2 id="licence-to-click">Licence to Click</h2>
<p>This wouldn&rsquo;t be very useful without software to use it.</p>
<p>To change a bit from Python, found a clean <a href="https://github.com/warthog618/gpio">Go lib</a> (that uses the sysfs interface) and made a simple one-button webapp <a href="https://github.com/fopina/rgrweb">rgrweb</a>.</p>
<p><img src="https://raw.githubusercontent.com/fopina/rgrweb/assets/Image.GIF" alt="rgrweb"></p>
<p>Added some testing flags to use it as a CLI tool. As there is feedback (after adding the second 4N25), it can be used to fully test the circuit wihout actually standing next to the garage door.</p>
<p><a href="https://asciinema.org/a/J1YR3McPxz5NykMiu7M9PcVxb?autoplay=1"><img src="https://asciinema.org/a/J1YR3McPxz5NykMiu7M9PcVxb.svg" alt="asciicast"></a></p>
<h2 id="the-word-is-not-enough">The Word is Not Enough</h2>
<p>Apologies for using <code>Garage Remote</code> in the title instead of <code>Garage Opener</code> (which I prefer and use in the rest of the text), but IoT pun called for it&hellip; Remote Garage Remote&hellip;</p>
]]></content></item><item><title>0xF8CB Pi TV - Lock HDMI Configuration</title><link>https://rpg.skmobi.com/posts/0xf8cb_pi_tv/</link><pubDate>Mon, 26 Oct 2020 12:31:53 +0000</pubDate><guid>https://rpg.skmobi.com/posts/0xf8cb_pi_tv/</guid><description>One of my raspberries is connected to the TV (quite original!) running RetroPie with Kodi as well.
Every now and then, power fails. When restored, the Pi always came up with messed up resolution.
I would just reboot it once again and everything would be fine, so I postponed looking into.
Turns out it was one of those things you delay because you think it will take forever to understand but in the end takes 5min&amp;hellip;</description><content type="html"><![CDATA[<p>One of my raspberries is connected to the TV (quite original!) running <a href="https://retropie.org.uk/">RetroPie</a> with Kodi as well.</p>
<p>Every now and then, power fails. When restored, the Pi always came up with messed up resolution.<br>
I would just reboot it once again and everything would be fine, so I postponed looking into.</p>
<p>Turns out it was one of those things you delay because you think it will take forever to understand but in the end takes 5min&hellip;</p>
<p>After a quick check I noticed the Pi would start with the wrong resolution because it booted faster than the TV. That&rsquo;s why reboot the Pi after would pick up the right resolution.</p>
<p>Decided to look into how to set fixed resolution and came across <a href="https://www.raspberrypi.org/forums/viewtopic.php?t=71756">this forum post</a>.</p>
<p>In short:</p>
<ul>
<li>
<p>Plug TV and boot Pi (so it autodetects the right resolution) and save current settings</p>
<pre><code>sudo tvservice -d /boot/edid.dat
</code></pre></li>
<li>
<p>Then update <code>/boot/config.txt</code></p>
<pre><code>hdmi_edid_file=1
</code></pre></li>
</ul>
]]></content></item><item><title>0x8490 Privileged Swarm Services</title><link>https://rpg.skmobi.com/posts/0x8490_privileged_swarm_service/</link><pubDate>Sat, 07 Mar 2020 14:38:07 +0000</pubDate><guid>https://rpg.skmobi.com/posts/0x8490_privileged_swarm_service/</guid><description>Some docker images require extra capabilities to work, ie:
openvpn needs NET_ADMIN anything using USB/i2c will need --device=/dev/ttyAMA0 Swarmkit does not support that (nor the GIEF IT ALL --privileged flag).
There are a lot of issues on their github(s) such as this, this or this.
It seems there is consensus into adding the feature to swarmkit though it won&amp;rsquo;t be available before 19.06 or 19.09.
Until then, the best solution seems to be spinning up a service that starts the container after, such as:</description><content type="html"><![CDATA[<p>Some docker images require extra capabilities to work, ie:</p>
<ul>
<li>openvpn needs <code>NET_ADMIN</code></li>
<li>anything using USB/i2c will need <code>--device=/dev/ttyAMA0</code></li>
</ul>
<p>Swarmkit does not support that (nor the GIEF IT ALL <code>--privileged</code> flag).</p>
<p>There are a lot of issues on their github(s) such as <a href="https://github.com/docker/swarmkit/issues/1030">this</a>, <a href="https://github.com/moby/moby/issues/25885">this</a> or <a href="https://github.com/moby/moby/pull/38380">this</a>.</p>
<p>It seems there is consensus into adding the feature to swarmkit though it won&rsquo;t be available before 19.06 or 19.09.</p>
<p>Until then, the best solution seems to be spinning up a service that starts the container after, such as:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;3.1&#39;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">services</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">web</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">docker:19.03</span><span class="w">
</span><span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="l">sh -c &#34;docker pull fopina/octoprint &amp;&amp; docker run </span><span class="w">
</span><span class="w">                        </span>--<span class="l">rm</span><span class="w">
</span><span class="w">                        </span>--<span class="l">name octoprint_real</span><span class="w">
</span><span class="w">                        </span>-<span class="l">v /nfs/path/to/octoprint/config:/root/.octoprint</span><span class="w">
</span><span class="w">                        </span>--<span class="l">device=/dev/ttyAMA0</span><span class="w">
</span><span class="w">                        </span>-<span class="l">p 5000:5000</span><span class="w">
</span><span class="w">                        </span><span class="l">fopina/octoprint&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="l">/var/run/docker.sock:/var/run/docker.sock</span><span class="w">
</span><span class="w">      </span>- <span class="l">/root/.docker:/root/.docker:ro</span><span class="w">
</span><span class="w">    </span><span class="nt">deploy</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l">replicated</span><span class="w">
</span><span class="w">      </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="nt">placement</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">constraints</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="l">node.hostname == printingPi]</span><span class="w">
</span></code></pre></div><p>Why would you use swarm service for this, since it&rsquo;s bound to the specific node where the USB cable is connected?</p>
<p>In this case, it&rsquo;s managing all <strong>services</strong> the same way, I don&rsquo;t want to deploy some with <code>docker-compose</code> and others with <code>docker swarm deploy</code>&hellip;</p>
<p>But in the case of, let&rsquo;s say <a href="https://rpg.skmobi.com/posts/0x6baa_openvpn/">openvpn</a>, it could be useful for easily scaling up across different nodes.</p>
<p>We could use a stack like the first:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;3.1&#39;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">services</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">vpnd</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">docker:19.03</span><span class="w">
</span><span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="l">docker run --rm</span><span class="w">
</span><span class="w">                        </span>--<span class="l">name openvpn_real</span><span class="w">
</span><span class="w">                        </span>--<span class="l">cap-add NET_ADMIN</span><span class="w">
</span><span class="w">                        </span>-<span class="l">p 443:443/udp</span><span class="w">
</span><span class="w">                        </span>-<span class="l">v /nfs/path/to/openvpn/:/etc/openvpn/</span><span class="w">
</span><span class="w">                        </span><span class="l">fopina/openvpn</span><span class="w">
</span><span class="w">    </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="l">/var/run/docker.sock:/var/run/docker.sock</span><span class="w">
</span><span class="w">    </span><span class="nt">deploy</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l">replicated</span><span class="w">
</span><span class="w">      </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="nt">placement</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">constraints</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="l">node.role == manager]</span><span class="w">
</span></code></pre></div><p>But as openvpn is not running in the actual service container, the port is not published in the swarm VIP / routing mesh.
If we can scale it up, it needs to end in different nodes (as there&rsquo;s an host bound port) and to make use of the replicas, we need to use the node IP (not <em>any</em> node IP as the usual routing mesh)&hellip;</p>
<p>My overkill solution:</p>
<ul>
<li>adding some proxy - just used <a href="https://linux.die.net/man/1/socat">socat</a> in my example</li>
<li>write an entrypoint script that
<ul>
<li>starts docker container (without binding port) attached to a common network with the service container</li>
<li>extract the IP from the new container</li>
<li>launch proxy using the same port</li>
<li>attach to container (so that main service process is the container itself, not the proxy)</li>
</ul>
</li>
<li>just use that port in the service description as if it was any other service</li>
</ul>
<p>To accomplish this, I&rsquo;ve created the image <a href="https://hub.docker.com/r/fopina/swarm-service-proxy">fopina/swarm-service-proxy</a> (built from <a href="https://github.com/fopina/docker-swarm-service-proxy">this</a>)</p>
<p>The stack definition using this is</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;3.1&#39;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">services</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">vpnd</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">fopina/swarm-service-proxy:1</span><span class="w">
</span><span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span>--<span class="l">rm</span><span class="w">
</span><span class="w">             </span>--<span class="l">cap-add NET_ADMIN</span><span class="w">
</span><span class="w">             </span>-<span class="l">v /nfs/path/to/openvpn/:/etc/openvpn/</span><span class="w">
</span><span class="w">             </span><span class="l">fopina/openvpn</span><span class="w">
</span><span class="w">    </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="l">/var/run/docker.sock:/var/run/docker.sock</span><span class="w">
</span><span class="w">    </span><span class="nt">environment</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">PROXIED_PORT</span><span class="p">:</span><span class="w"> </span><span class="m">443</span><span class="w">
</span><span class="w">      </span><span class="nt">PROXIED_PROTO</span><span class="p">:</span><span class="w"> </span><span class="l">udp</span><span class="w">
</span><span class="w">      </span><span class="nt">PROXIED_NAME</span><span class="p">:</span><span class="w"> </span><span class="l">openvpn_real</span><span class="w">
</span><span class="w">    </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="m">443</span><span class="p">:</span><span class="m">443</span><span class="l">/udp</span><span class="w">
</span><span class="w">    </span><span class="nt">deploy</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l">replicated</span><span class="w">
</span><span class="w">      </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></code></pre></div><p>With this, port is actually published from the service (not to the secondary container) so it makes use of the routing mesh (and it doesn&rsquo;t lock the port in the docker host where it lands).</p>
<p>Syntax remained as close as possible to the initial version: command is used as if it was <code>docker run &lt;command&gt;</code>.</p>
<ul>
<li><code>PROXIED_PORT</code> is the internal port of the secondary container.</li>
<li>Use <code>PROXIED_PROTO: udp</code> if <code>socat</code> should use the UDP labels (instead of TCP).</li>
<li>Use <code>PROXIED_NAME</code> to choose the name <em>prefix</em> of the secondary container - yes, <em>prefix</em> as random string is appended to it to make sure it will not collide if scaled up.</li>
<li>Do not forget to bind the port you need in the service</li>
<li>Do not publish any port on the secondary container (as it won&rsquo;t be used)</li>
</ul>
<p>So it is now fully managed as it was a service and fully scalable.</p>
]]></content></item><item><title>0x6BAA OpenVPN Made Easy</title><link>https://rpg.skmobi.com/posts/0x6baa_openvpn/</link><pubDate>Sun, 15 Dec 2019 18:54:23 +0000</pubDate><guid>https://rpg.skmobi.com/posts/0x6baa_openvpn/</guid><description>Why Some people decide to buy some external VPN service for privacy.
Personally, as I already commit all my internet usage to my ISP at home, I rather VPN from untrusted locations into my home instead, saving a few bucks and keeping my ISP as the sole entity holding that information.
I guess I could try to use one of those VPN services (with better privacy terms than my ISP) at home but that would increase complexity too much for the rest of the household</description><content type="html"><![CDATA[<h2 id="why">Why</h2>
<p>Some people decide to buy some external VPN service for privacy.<br>
Personally, as I already commit all my internet usage to my ISP at home, I rather VPN from <em>untrusted locations</em> into my home instead, saving a few bucks and keeping my ISP as the sole entity holding that information.<br>
I guess I could try to use one of those VPN services (with better privacy terms than my ISP) at home but that would increase complexity too much for the rest of the <em>household</em></p>
<p>As I already had some <a href="https://www.raspberrypi.org/">raspberries</a>, <a href="https://github.com/fopina/docker-openvpn/">forking</a> <a href="https://github.com/kylemanna/docker-openvpn/">kylemanna/docker-openvpn</a> to build it for <strong>arm</strong> was the quickest way, some years ago.</p>
<p>Recently, some people have asked how to use the same docker image quickly in their raspberries, so I took the opportunity to refresh the docker image and add some goodies and I&rsquo;ll summarize the quickstart here.</p>
<h2 id="how">How</h2>
<ol>
<li>Install <a href="https://www.raspberrypi.org/documentation/installation/installing-images/README.md">raspbian</a> on your Pi (or any other language that supports docker)</li>
<li>Install <a href="https://docs.docker.com/v17.09/engine/installation/linux/docker-ce/debian/">Docker CE</a></li>
<li>Run this docker</li>
</ol>
<p>First 2 steps are well documented already, let&rsquo;s focus on the third.</p>
<p>Setting it up in less than 3min</p>
<p><a href="https://asciinema.org/a/2vyMJDZ76nTQQz3uvIxNyWoCF"><img src="https://asciinema.org/a/2vyMJDZ76nTQQz3uvIxNyWoCF.svg" alt="asciicast"></a></p>
<h3 id="drill-down">Drill down</h3>
<ol>
<li>
<p>Initialize the configuration directory</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker run --rm <span class="se">\
</span><span class="se"></span>        -v testvpn:/etc/openvpn <span class="se">\
</span><span class="se"></span>        fopina/openvpn <span class="se">\
</span><span class="se"></span>        ovpn_genconfig -u udp://my.external.ip:9999
</code></pre></div><p><code>testvpn</code> used like this will be a <a href="https://docs.docker.com/storage/volumes/">named volume</a> which is probably the cleanest and easiest option for most cases.<br>
If you want to make configuration files available to the host filesystem or if you&rsquo;re using this in a <a href="https://docs.docker.com/engine/swarm/">swarm</a>, then you don&rsquo;t use a named volume&hellip;<br>
<code>udp://my.external.ip:9999</code> can be <code>tcp://</code> instead if you need to use TCP for some reason, but <a href="http://sites.inka.de/bigred/devel/tcp-tcp.html">avoid if possible</a>.<br>
<code>9999</code> will be port exposed publicly (in your router, for instance), not the one published by the container - might be the same but not necessarily.</p>
</li>
<li>
<p>Generate CA</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker run --rm -ti <span class="se">\
</span><span class="se"></span>           -v testvpn:/etc/openvpn <span class="se">\
</span><span class="se"></span>           fopina/openvpn <span class="se">\
</span><span class="se"></span>           ovpn_initpki
</code></pre></div><p>Nothing much to say, just pick a passphrase for the CA that will be used to issue client certificates.</p>
</li>
<li>
<p>Start the service</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker run -v testvpn:/etc/openvpn <span class="se">\
</span><span class="se"></span>           -d -p 9999:1194/udp <span class="se">\
</span><span class="se"></span>           --restart<span class="o">=</span>always <span class="se">\
</span><span class="se"></span>           --cap-add<span class="o">=</span>NET_ADMIN <span class="se">\
</span><span class="se"></span>           fopina/openvpn
</code></pre></div><p><code>-p 9999:1194/udp</code></p>
<ul>
<li>you can choose other published port instead of <code>9999</code></li>
<li>Leave the internal port <code>1194</code> as that one never changes</li>
<li>Adjust <code>udp</code> to <code>tcp</code> if you used TCP in the first step</li>
</ul>
</li>
<li>
<p>Generate client configuration</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker run --rm -ti <span class="se">\
</span><span class="se"></span>           -v testvpn:/etc/openvpn <span class="se">\
</span><span class="se"></span>           fopina/openvpn <span class="se">\
</span><span class="se"></span>           easyrsa build-client-full CLIENTNAME nopass
</code></pre></div><ul>
<li><code>CLIENTNAME</code> should be whatever identifier you want for that profile/device</li>
<li>remove <code>nopass</code> if you want the profile to have a password (that you will to enter everytime you connect)</li>
</ul>
</li>
<li>
<p>Generate .ovpn and download link</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker run --rm <span class="se">\
</span><span class="se"></span>           -v testvpn:/etc/openvpn <span class="se">\
</span><span class="se"></span>           fopina/openvpn:helper <span class="se">\
</span><span class="se"></span>           ovpn_getclient_link CLIENTNAME
</code></pre></div><p>This will bundle the previous step into an .ovpn file, upload it to <a href="https://vim.cx">vim.cx</a> (which is a <a href="https://privatebin.info/">PrivateBin</a> instance that supports attachments) and generate a QR code to make it easier to copy to a mobile device.
If you prefer to manage the file transfer yourself, you can use:</p>
<div class="highlight"><pre class="chroma"><code class="language-shell" data-lang="shell">docker run --rm <span class="se">\
</span><span class="se"></span>           -v testvpn:/etc/openvpn <span class="se">\
</span><span class="se"></span>           fopina/openvpn <span class="se">\
</span><span class="se"></span>           ovpn_getclient CLIENTNAME &gt; CLIENTNAME.ovpn
</code></pre></div></li>
</ol>
<h2 id="done-references">Done: references</h2>
<ul>
<li><a href="https://github.com/fopina/privatebin">CLI</a> used to upload attachments to privatebin</li>
<li><a href="https://github.com/fumiyas/qrc">CLI</a> used to generate the QR codes in the terminal</li>
<li><a href="https://github.com/fopina/docker-openvpn/blob/master/.github/workflows/main.yml">this github workflow</a> to make the multi-platform builds of the docker image</li>
</ul>
<p>Enjoy your home VPN.</p>
]]></content></item><item><title>0xD755 Free Log Collection</title><link>https://rpg.skmobi.com/posts/0xd755_gcp_logging/</link><pubDate>Wed, 10 Jul 2019 00:47:31 +0100</pubDate><guid>https://rpg.skmobi.com/posts/0xd755_gcp_logging/</guid><description>I have a few raspberries lying around the house plus a couple of really cheap low-end VPS (1‚Ç¨ arubas)
Not only they there are containers, cron jobs, etc spread among them (but all keep under ansible control) 2 of them are a docker swarm cluster with replicas for same services.
Eventually I need to check logs for something (and I&amp;rsquo;d also like to keep tabs on cpu/memory/disk metrics), so I started looking into log management/collection solutions.</description><content type="html"><![CDATA[<p>I have a few <a href="https://www.raspberrypi.org/">raspberries</a> lying around the house plus a couple of <del>really cheap</del> low-end VPS (1‚Ç¨ <a href="https://www.arubacloud.com/">arubas</a>)</p>
<p>Not only they there are containers, cron jobs, etc spread among them (but all keep under ansible control) 2 of them are a docker swarm cluster with replicas for same services.</p>
<p>Eventually I need to check logs for something (and I&rsquo;d also like to keep tabs on cpu/memory/disk metrics), so I started looking into log management/collection solutions.
As these are for personal projects, I always try to go for <del>free</del> low-cost solutions.</p>
<p>Self-hosting <a href="https://www.graylog.org/">Graylog</a> or <a href="https://www.splunk.com/en_us/software/features-comparison-chart.html">Splunk Free</a> is not an option as they would barely run on any of these options, plus avoiding storage costs is nice.</p>
<ul>
<li><a href="https://www.loggly.com/plans-and-pricing/">Loggly</a> has a nice free Lite plan</li>
<li><a href="https://papertrailapp.com/plans">Papertrail</a> has a really shitty one</li>
</ul>
<p>Probably a few more out there that I could not find before bumping into&hellip;. <a href="https://cloud.google.com/stackdriver/">GCP Stackdriver</a>
Thanks to the always-free plan Google and Amazon now have, Stackdriver is also included there. With 50GB ingestion per month!</p>
<p>Quickly testing <a href="https://cloud.google.com/logging/docs/agent/installation">their setup guide</a> in one of my VPS gets the logs flowing into (and showing in) <a href="https://console.cloud.google.com/logs/viewer">Log Viewer</a>, awesome!</p>
<p>Issue <strong>uno</strong>: they only have a <em>x86</em> package (as they only support GCP and AWS VMs) and that would leave raspberries out of the party&hellip; But looking at the package content it is just embedded ruby with <a href="https://www.fluentd.org/">fluentd</a> and <a href="https://github.com/GoogleCloudPlatform/fluent-plugin-google-cloud">their own output plugin</a> gems installed.
Installing the gems (in a ruby docker) in one of the raspberries and it was working.</p>
<p>But this brings up Issue <em>dos</em>: ruby!
Who uses ruby? Why?
Fluentd immediately started with 100MB of used memory and grew up to 300MB. Tuning garbage collector helped a little, but not nearly enough. Can&rsquo;t have the log collector using 10 or 15% of the server memory&hellip;</p>
<p>Ranting about it at work, someone mentions <a href="https://fluentbit.io/">Fluentbit</a>, fluentd in C (with Go plugins)!
Good looking <a href="https://docs.fluentbit.io/manual/installation/td-agent-bit">documentation</a> and in an hour or so, I had the logs in Stackdriver but using 1% of memory instead of 10%!</p>
<p>Instead of writing how to set it up or install it, I&rsquo;ll leave ansible to show for itself, with the role and playbook I used to then apply this to every machine.</p>
<p>The <em>generic</em> role:</p>
<script type="application/javascript" src="https://gist.github.com/fopina/c0439fa29bb7f3fa541a2d81a3f4a1e7.js"></script>

<p>And the playbook to set it up in all the machines</p>
<script type="application/javascript" src="https://gist.github.com/fopina/eea83d290f634566b2e68e31d9ba6a74.js"></script>

<p>Docker was configured (in another role) with <code>journald</code> as default logger, that&rsquo;s why I&rsquo;m using <a href="https://docs.fluentbit.io/manual/input/systemd">systemd input</a>.
Also added a few modify filters to reduce the clutter (and avoid hitting the ingestion limit at some point).</p>
<p>Pushing cpu and memory to use <a href="https://console.cloud.google.com/logs/metrics">Logs-based metrics</a>, but that&rsquo;ll be for another day&hellip;</p>
]]></content></item><item><title>0xC53E Peculiar Lenticular</title><link>https://rpg.skmobi.com/posts/0xc53e_lenticular/</link><pubDate>Sun, 30 Jun 2019 18:22:48 +0100</pubDate><guid>https://rpg.skmobi.com/posts/0xc53e_lenticular/</guid><description>I needed a symbolic gift some time ago and thought a lenticular keychain but the shops I found to get a custom made one would take over 2 weeks to deliver.
Googling a bit for DIY seems the only thing required to print lenticulars is image processing and lenticular lens. Again, getting lenticular lens was not so easy as it looked, so off and found this video, that looks easy!</description><content type="html"><![CDATA[<p>I needed a symbolic gift <a href="https://lmgtfy.com/?q=mother%27s+day+2019">some time ago</a> and thought a <a href="https://www.alibaba.com/product-detail/2019-Best-Selling-3D-Lenticular-Keychain_62131838666.html?spm=a2700.7724857.normalList.20.5c2525d9YnhbZr&amp;s=p">lenticular keychain</a> but the shops I found to get a custom made one would take over 2 weeks to deliver.</p>
<p>Googling a bit for DIY seems the only thing required to print lenticulars is image processing and lenticular lens.
Again, getting lenticular lens was not so easy as it looked, so off and found <a href="https://www.youtube.com/watch?v=mmGB9ADKr5Y">this video</a>, that looks easy!</p>
<p>Printing photos, cutting in several stripes and putting them all back together seemed like something to scripted though, hence</p>
<script type="application/javascript" src="https://gist.github.com/fopina/6e97829e33de8a8c72c2d1bf65ed5ab9.js"></script>

<h3 id="example">Example</h3>
<p><img src="b.png" alt="image 1"><img src="o.png" alt="image 2"></p>
<p>Running</p>
<pre><code>python lenticular.py b.png o.png
</code></pre><p>Yields</p>
<p><img src="tmp2p9xKb.png" alt="result image"></p>
]]></content></item><item><title>0x0000 The Seed</title><link>https://rpg.skmobi.com/posts/0x0000_the_seed/</link><pubDate>Tue, 07 May 2019 01:37:07 +0100</pubDate><guid>https://rpg.skmobi.com/posts/0x0000_the_seed/</guid><description>Sometimes we need something and we can&amp;rsquo;t find a straight up how-to online.
We put a few pieces together, get it done but wonder if we ever need to do it again, will we find the same resources again? Will they be up? Will we follow the same links?
We want to record our steps to remember later on, but we also want Google to index them so we get there, so why not post them up somewhere?</description><content type="html"><![CDATA[<p>Sometimes we need something and we can&rsquo;t find a straight up how-to online.</p>
<p>We put a few pieces together, get it done but wonder if we ever need to do it again, will we find the same resources again? Will they be up? Will we follow the same links?</p>
<p>We want to record our steps to remember later on, but we also want Google to index them so we get there, so why not post them up somewhere?</p>
<p>Internet is not running out of space.</p>
<p>In my case, I decided to dump everything here, RPG.</p>
<p>I&rsquo;ll start with how to set up a blog like this one:</p>
<ul>
<li><a href="https://gohugo.io">Hugo</a></li>
<li>on <a href="https://pages.github.com/">Github Pages</a></li>
<li>&hellip; with <a href="https://help.github.com/en/articles/using-a-custom-domain-with-github-pages">custom CNAME</a></li>
<li>published by <a href="https://travis-ci.org/">Travis CI</a></li>
</ul>
<h2 id="step-1---hugo-quickstart">Step 1 - Hugo quickstart</h2>
<p>Follow <a href="https://gohugo.io/getting-started/quick-start/">Hugo quick.start</a> to get a basic page running.</p>
<pre><code>‚ûú  hugo new site quickstart
Congratulations! Your new Hugo site is created in quickstart.

Just a few more steps and you're ready to go:

1. Download a theme into the same-named folder.
   Choose a theme from https://themes.gohugo.io/, or
   create your own with the &quot;hugo new theme &lt;THEMENAME&gt;&quot; command.
2. Perhaps you want to add some content. You can add single files
   with &quot;hugo new &lt;SECTIONNAME&gt;/&lt;FILENAME&gt;.&lt;FORMAT&gt;&quot;.
3. Start the built-in live server via &quot;hugo server&quot;.

Visit https://gohugo.io/ for quickstart guide and full documentation.
‚ûú  cd quickstart
‚ûú  git init
Initialized empty Git repository in quickstart/.git/
‚ûú  git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke
Cloning into 'quickstart/themes/ananke'...
remote: Enumerating objects: 17, done.
remote: Counting objects: 100% (17/17), done.
remote: Compressing objects: 100% (15/15), done.
remote: Total 1349 (delta 3), reused 13 (delta 2), pack-reused 1332
Receiving objects: 100% (1349/1349), 4.14 MiB | 3.08 MiB/s, done.
Resolving deltas: 100% (722/722), done.
‚ûú  echo theme = \&quot;ananke\&quot; &gt;&gt; config.toml
‚ûú  hugo new posts/my-first-post.md
quickstart/content/posts/my-first-post.md created
</code></pre><p>If you run <code>hugo server -D</code> you should be able to open up http://localhost:1313/ and check your brand new blog with one empty post.</p>
<h2 id="step-2---github-pages">Step 2 - Github pages</h2>
<ul>
<li>Create a <a href="https://github.com/">GitHub</a> repository</li>
<li>Add it to your local repo and push</li>
</ul>
<pre><code>‚ûú  git remote add origin git@github.com:YOURUSER/YOURREPO.git
‚ûú  git push -u origin master
</code></pre><ul>
<li>Publish the site to branch <code>gh-pages</code></li>
</ul>
<pre><code>‚ûú  hugo -d /tmp/whatever
‚ûú  git checkout --orphan gh-pages
‚ûú  rm -fr *
‚ûú  rm .gitmodules
‚ûú  cp -a /tmp/whatever/* .
‚ûú  git add .
‚ûú  git push -u origin gh-pages
</code></pre><ul>
<li>Go to your GitHub project settings and enable <code>GitHub Pages</code> with <code>gh-pages branch</code> as <code>source</code></li>
</ul>
<p>After a couple of minutes <em>your brand new blog wit one empty post</em> should be available at <a href="https://YOURUSER.github.io/YOURREPO">https://YOURUSER.github.io/YOURREPO</a></p>
<h2 id="step-3---extra---custom-cname">Step 3 - EXTRA - Custom CNAME</h2>
<p>If you&rsquo;d rather use your own (sub)domain (such as <a href="https://rpg.skmobi.com/):">https://rpg.skmobi.com/):</a></p>
<ul>
<li>Add the (sub)domain to a file named <code>CNAME</code> in the root of the master branch like <a href="https://github.com/fopina/rpg/blob/master/CNAME">this</a></li>
<li>Setup your DNS with CNAME record pointing to <code>YOURUSER.github.io</code></li>
<li>As GitHub pages now supports HTTPS on custom domains (using <a href="https://letsencrypt.org/">LetsEncrypt</a>), I&rsquo;d recommend ticking <code>Enforce HTTPS</code> in <code>GitHub Pages</code> section of the project settings</li>
</ul>
<h2 id="step-4---travis-ci">Step 4 - Travis-CI</h2>
<p>As the last step, you can use <a href="https://travis-ci.org/">Travis-CI</a> to automate publishing when pushing new Hugo content.
Original idea taken from <a href="https://www.sidorenko.io/post/2018/12/hugo-on-github-pages-with-travis-ci/">this post</a>.</p>
<ul>
<li>(Optionally) Create a second (bot) GitHub account and add it as collaborator of your repository. This allows you to add this account credentials to Travis instead of your main one.</li>
<li>Signup to <a href="https://travis-ci.org/">Travis-CI</a> and enable it for your repository
<a href="https://www.sidorenko.io/post/2018/12/hugo-on-github-pages-with-travis-ci/">https://www.sidorenko.io/post/2018/12/hugo-on-github-pages-with-travis-ci/</a></li>
<li>In <code>Environment Variables</code> of <code>Settings</code> of this Travis project, create the variable <code>GITHUB_AUTH_SECRET</code> with the content <code>https://USERNAME:PASSWORD@github.com/YOURUSER/YOURREPO</code>. Use your bot account here if you decided to create one.</li>
<li>Create the file <code>deploy.sh</code> in your <code>master</code> branch root</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="cp">#!/bin/bash
</span><span class="cp"></span>
<span class="nb">set</span> -e

<span class="nb">echo</span> <span class="nv">$GITHUB_AUTH_SECRET</span> &gt; ~/.git-credentials <span class="o">&amp;&amp;</span> chmod <span class="m">0600</span> ~/.git-credentials
git config --global credential.helper store
git config --global user.email <span class="s2">&#34;GITHUB_USER@users.noreply.github.com&#34;</span>
git config --global user.name <span class="s2">&#34;Publishing bot&#34;</span>
git config --global push.default simple

git fetch origin gh-pages
git checkout FETCH_HEAD
git checkout -b gh-pages
rm -fr *
mv ../public/* .
rmdir ../public/
git add -A
git commit -m <span class="s2">&#34;rebuilding site on `date`, commit </span><span class="si">${</span><span class="nv">TRAVIS_COMMIT</span><span class="si">}</span><span class="s2"> and job </span><span class="si">${</span><span class="nv">TRAVIS_JOB_NUMBER</span><span class="si">}</span><span class="s2">&#34;</span> <span class="o">||</span> <span class="nb">true</span>
git push origin gh-pages
</code></pre></div><ul>
<li>And finally, the <code>.travis.yml</code>, also in your <code>master</code> branch root</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">language</span><span class="p">:</span><span class="w"> </span><span class="l">minimal</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">install</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="l">wget -O /tmp/hugo.deb https://github.com/gohugoio/hugo/releases/download/v0.55.0/hugo_0.55.0_Linux-64bit.deb</span><span class="w">
</span><span class="w">  </span>- <span class="l">sudo dpkg -i /tmp/hugo.deb</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">script</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="l">hugo -d ../public</span><span class="w">
</span><span class="w">  </span>- <span class="l">cp CNAME ../public</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">deploy</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">provider</span><span class="p">:</span><span class="w"> </span><span class="l">script</span><span class="w">
</span><span class="w">    </span><span class="nt">script</span><span class="p">:</span><span class="w"> </span><span class="l">./deploy.sh</span><span class="w">
</span><span class="w">    </span><span class="nt">skip_cleanup</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="nt">on</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">branch</span><span class="p">:</span><span class="w"> </span><span class="l">master</span><span class="w">
</span></code></pre></div><p>Commit these 2 files, push them and you&rsquo;re done! Travis job should kick off and <code>gh-pages</code> branch will be automatically updated, as will your blog.</p>
]]></content></item></channel></rss>